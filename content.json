{"pages":[{"title":"关于我","text":"基本信息 姓名: ? 学历: 在读研究生(国防科技大学计算机专业) 籍贯：重庆 联系我 邮箱: 1034310781@qq.com 博客: https://me.csdn.net/weixin_41134246 知乎: https://www.zhihu.com/people/he-yu-lin-39 github: https://github.com/harrylin-hyl 研究方向 Deep Learning CV Machine Learning 研究项目 人脸识别和检测 医疗病理图像识别 医疗PDL-1细胞检测识别和分割 点监督细胞定位 兴趣方向 AutoML Cloud Point Meta Learning Reinforce Learning 如果有志同道合的朋友可以联系我，共同成长和进步！ 💪💪💪","link":"/about/index.html"}],"posts":[{"title":"Github+Hexo+icarus创建自定义blog","text":"使用Github+Hexo+icarus创建自定义blog 在GitHub上申请个人主页 详情参考：如何在GitHub上面建立自己的个人主页简要介绍Hexo的安装与主题的切换。详细的安装方式与配置请参考官方文档 安装Hexo 需要环境： Node.js &gt;= 8.x Git 了解Hexo： 搭建一个属于自己的个人网站!GitHub+Hexo搭建个人网站 安装Hexo12345npm install hexo-cli -ghexo init blogcd blognpm installhexo server 配置主题cd blog # 使用git将主题下载到themes目录 git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarusHexo可以有很多主题，可以在官网中看到很多漂亮的主题，可以根据自己的爱好进行选择，这里我选择了icarus主题，个人感觉简单大方。 FAQ 重新执行hexo serve命令，发现报错如下： ERROR Package cheerio is not installed.ERROR Please install the missing dependencies from the root directory of your Hexo site. 原因缺少cheerio依赖，进入blog-hexo目录，执行npm i cheerio -S命令进行安装即可，-S指安装并将其保存到当前项目的配置中，下次就会统一安装了。 重新执行hexo serve命令，发现如下信息： INFO Checking dependenciesINFO Validating the configuration fileWARN themes/icarus/_config.yml is not found. We are creating one for you…INFO themes/icarus/_config.yml is created. Please restart Hexo to apply changes. 只是提示缺少themes/icarus/_config.yml文件，已经帮助我们生成，再次运行即可正常启动。 个性化设置所谓的个性化设置就是根据个人需要添加不同的插件及功能。基本信息是在主题中的_config.yml进行修改，其他外观布局等分别有各自的文件夹和文件管理。网上有很多的个性设置教程，下面就添加一些优秀的链接： hexo及icarus主题个性定制 Hexo+icarus主题配置","link":"/2020/02/02/github+hexo+icarus%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89blog/"},{"title":"为自定义博客添加评论功能","text":"为自定义博客添加评论功能,介绍基本的方法，主要使用gitalk来实现 介绍一些支持的评论模块具体支持哪些可以看icarus/layout/comment文件夹中的一系列文件。如果要加自己的就要自己添加文件。最开始就想用github来作为用户进行评论，然后看到gitment模块，踩了很多坑，然后强烈推荐gitalk。因为一些原因gitment的服务器不再维护了，所以工作量就变得很大，不建议使用。具体可以看: gitment修复[object ProgressEvent] hexo博客的gitment评论开启一直失败 使用hexo + gitalk参考博客 首先Github上，注册 OAuth Application可以通过这个地址来注册一个应用，按提示填写即可。 成功之后会得到一个client ID 和一个 client secret，在后面的初始化插件时会用到。 修改主题中的_config.yml文件修改coment下面的代码 comment: type: gitalk owner: xxx (harrylin-hyl) # (required) GitHub user name repo: xxx (harrylin-hyl.github.io) # (required) GitHub repository name client_id: xxxxxxx # (required) OAuth application client id 上面生成的 client_secret: xxxxxx # (required) OAuth application client secret 上面生成的 admin: xxx (harrylin-hyl) #此账户一般为用户名 GitHub user name 文章中能创建issue需要此用户登录才可以，点了创建issue后刷新一遍才能看到！！！！ create_issue_manually: true distraction_free_mode: true 重新刷新一下，重启一下hexo就可以了，以下是效果图：","link":"/2020/02/02/%E4%B8%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"},{"title":"PointNet系列方法","text":"PointNet系列处理点云的方法:PointNet、PointNet++、Frustum-PointNet和FlowNet3D 1. PointNet系列 参考：https://zhuanlan.zhihu.com/p/44809266 点云三大性质： 无序性。点云集合顺序不敏感，意味着处理点云数据的模型需要对数据的不同排列保持不变性。目前文献中使用的方法包括将无序的数据重排序、用数据的所有排列进行数据增强然后使用RNN模型、用对称函数来保证排列不变性。由于第三种方式的简洁性且容易在模型中实现，论文作者选择使用第三种方式，既使用maxpooling这个对称函数来提取点云数据的特征。 点与点之间的空间关系。一个物体通常由特定空间内的一定数量的点云构成，也就是说这些点云之间存在空间关系。为了能有效利用这种空间关系，论文作者提出了将局部特征和全局特征进行串联的方式来聚合信息。 不变性。点云数据所代表的目标对某些空间转换应该具有不变性，如旋转和平移。论文作者提出了在进行特征提取之前，先对点云数据进行对齐的方式来保证不变性。对齐操作是通过训练一个小型的网络来得到转换矩阵，并将之和输入点云数据相乘来实现(T-Net)。 2. PointNet PointNet的模型结构如上图所示，其关键流程介绍如下： 输入为一帧的全部点云数据的集合，表示为一个nx3的2d tensor，其中n代表点云数量，3对应xyz坐标。 输入数据先通过和一个T-Net学习到的转换矩阵相乘来对齐，保证了模型的对特定空间转换的不变性。 通过多次mlp对各点云数据进行特征提取后，再用一个T-Net对特征进行对齐。 在特征的各个维度上执行maxpooling操作来得到最终的全局特征。 对分类任务，将全局特征通过mlp来预测最后的分类分数；对分割任务，将全局特征和之前学习到的各点云的局部特征进行串联，再通过mlp得到每个数据点的分类结果。 网络重要组成介绍 T-Net：针对平移或者旋转情况，设计的自适应网络。可学习的一个旋转矩阵，输出$k_1 * k_2$的矩阵，$k_1$是输入层数，$k_2$是输出层数。 MLP：多层感知机。图中有share的地方用的是1x1卷积表示，每层共享权重。没有share部分直接用的全连接层。 分为分类网络和分割网络。分类网络对整个点云分类，分割网络对每一个点分类。顺序和输入点云顺序一致。 3. PointNet++ 网络构成PointNet提取特征的方式是对所有点云数据提取了一个全局的特征，显然，这和目前流行的CNN逐层提取局部特征的方式不一样。受到CNN的启发，作者提出了PointNet++，它能够在不同尺度提取局部特征，通过多层网络结构得到深层特征。PointNet++由以下几个关键部分构成： 采样层（sampling）激光雷达单帧的数据点可以多达100k个，如果对每一个点都提取局部特征，计算量是非常巨大的。因此，作者提出了先对数据点进行采样。作者使用的采样算法是最远点采样（farthest point sampling, FPS），相对于随机采样，这种采样算法能够更好地覆盖整个采样空间。 组合层（grouping）为了提取一个点的局部特征，首先需要定义这个点的“局部”是什么。一个图片像素点的局部是其周围一定曼哈顿距离下的像素点，通常由卷积层的卷积核大小确定。同理，点云数据中的一个点的局部由其周围给定半径划出的球形空间内的其他点构成。组合层的作用就是找出通过采样层后的每一个点的所有构成其局部的点，以方便后续对每个局部提取特征。 特征提取层（feature learning）因为PointNet给出了一个基于点云数据的特征提取网络，因此可以用PointNet对组合层给出的各个局部进行特征提取来得到局部特征。值得注意的是，虽然组合层给出的各个局部可能由不同数量的点构成，但是通过PointNet后都能得到维度一致的特征（由上述K值决定）。 上述各层构成了PointNet++的基础处理模块。如果将多个这样的处理模块级联组合起来，PointNet++就能像CNN一样从浅层特征得到深层语义特征。对于分割任务的网络，还需要将下采样后的特征进行上采样，使得原始点云中的每个点都有对应的特征。这个上采样的过程通过最近的k个临近点进行插值计算得到。 4. Frustum-PointNet 上述的PointNet和PointNet++主要用于点云数据的分类和分割问题，Frustum-PointNet（F-PointNet）将PointNet的应用拓展到了3D目标检测上。目前单纯基于Lidar数据的3D目标检测算法通常对小目标检测效果不佳，为了处理这个问题，F-PointNet提出了结合基于图像的2D检测算法来定位目标，再用其对应的点云数据视锥进行bbox回归的方法来实现3D目标检测。F-PointNet的网络结构如下图所示。可以看到，F-PointNet主要由以下几部分构成： 视锥生成（frustum proposal）：首先通过2D目标检测器来定位图片中的目标以及判断它们的类别。对每一个检测到的目标，通过标定好的传感器的内参和它们之间的转换矩阵得到其对应的点云数据中的各点，即点云视锥。作者使用的2D目标检测模型是基于VGG网络的FPN作为特征提取器，并用Fast R-CNN来预测最终的2D bbox。 3D实例分割（3D instance segmentation）:对每个得到的点云视锥，通过旋转得到以中心视角为坐标轴的点云数据。对转换后的点云数据用PointNet（或PointNet++）进行实例分割。实例分割是一个二分类问题，用于判断每个点属于某个目标或者不属于。 3D边界框回归（3D box estimation）:将上一步实例分割的结果作为mask得到属于某个实例的所有点云，计算其质心作为新的坐标系原点。通过一个T-Net进行回归得到目标质心和当前坐标原点的残差。将点云平移到计算得到的目标质心后，通过PointNet（或PointNet++）对3D bbox的中心、尺寸和朝向进行回归得到最终的输出。此步骤采用的回归方式和Faster R-CNN中类似，不直接回归，而是回归到不同尺寸和朝向的锚点（anchors）。 综上所述，F-PointNet是一个多步骤的3D目标检测算法。如下图所示，为了应对点云数据中各个目标的视角不变性和得到更准确的bbox回归（通过缩小需要回归的值的取值范围），算法需要进行三次坐标转换。模型的loss和2D的目标检测一样是包含分类以及回归的多任务loss。同时，作者提出了一种被称为corner loss的损失函数来对目标的中心、朝向和大小进行联合优化，避免由于某一方面的不准确而主导loss。 详细参考： https://blog.csdn.net/u011507206/article/details/89106892 5. FlowNet3D: Learning Scene Flow in 3D Point Clouds 通过点云预测光流，整个流程如图所示：后融合之后再进行特征聚合输出最后的结果。set_conv用的pointnet++的结构。flow embedding层来进行前后两帧的差异性提取：set_upconv用上采样和前面下采样的特折进行skip操作。","link":"/2020/02/04/PointNet%E7%B3%BB%E5%88%97/"},{"title":"点云采样","text":"有关点云采样的方法： 格点采样、均匀采样、几何采样 格点采样格点采样，就是把三维空间用格点离散化，然后在每个格点里采样一个点。具体方法如下： 创建格点：如中间图所示，计算点云的包围盒，然后把包围盒离散成小格子。格子的长宽高可以用户设定，也可以通过设定包围盒三个方向的格点数来求得。 每个小格子包含了若干个点，取离格子中心点最近的点为采样点，如右图所示。 格点采样的特点： 效率非常高 采样点分布比较均匀，但是均匀性没有均价采样高 可以通过格点的尺寸控制点间距 不能精确控制采样点个数 均匀采样均匀采样的方法有很多，并且有一定的方法来评估采样的均匀性。这里介绍一种简单的均匀采样方法，最远点采样。具体方法如下： 输入点云记为C，采样点集记为S，S初始化为空集。 随机采样一个种子点Seed，放入S。如图1所示。 每次采样一个点，放入S。采样的方法是，在集合C-S里，找一点距离集合S距离最远的点。其中点到集合的距离为，这点到集合里所有点距最小的距离。如图2-6所示，采样点S的数量分别为2，4，10，20，100. 最远点采样的特点： 采样点分布均匀 算法时间复杂度有些高，因为每次采样一个点，都要计算集合到集合之间的距离。可以采用分治的方法来提高效率。 采样点一般先分布在边界附近，这个性质在有些地方是有用的，比如图元检测里面的点采样。 几何采样几何采样，在点云曲率越大的地方，采样点个数越多。下面介绍一种简单的几何采样方法，具体方法如下： 输入是一个点云，目标采样数S，采样均匀性U 点云曲率计算比较耗时，这里我们采用了一个简单方法，来近似达到曲率的效果：给每个点计算K邻域，然后计算点到邻域点的法线夹角值。曲率越大的地方，这个夹角值就越大。 设置一个角度阈值，比如5度。点的邻域夹角值大于这个阈值的点，被放入几何特征区域G。这样点云就分成了两部分，几何特征区域G和其它区域。 均匀采样几何特征区域G和其它区域，采样数分别为S * (1 - U)，S * U。 这个采样方法的特点： 几何特征越明显的区域，采样点个数分布越多 计算效率高 采样点局部分布是均匀的 稳定性高：通过几何特征区域的划分，使得采样结果抗噪性更强","link":"/2020/02/01/%E7%82%B9%E4%BA%91%E9%87%87%E6%A0%B7/"},{"title":"语义分割中的损失","text":"有关图像语义分割的一系列改进loss 常用loss: CE BCE WCE Focal loss Dice loss IOU loss Tversky loss 敏感性–特异性 loss Generalized Dice loss BCE + Dice loss Dice + Focal loss Exponential Logarithmic loss以上部分有一篇博客讲得比较清楚：原文博客链接: (https://blog.csdn.net/m0_37477175/article/details/83004746) Lov´asz-Softmaxloss请看我的另一篇博客：（https://blog.csdn.net/weixin_41134246/article/details/103280203）对采样进行改进的loss Boundary loss 提出generalized Dice loss，对Dice loss在计算中加上权重，主要是为了解决样本不平衡问题。 根据这一个权重函数可以看出来，$r_{ln}$代表这一个类的label map之和，当这一个类别像素值少的时候权重会变大，像素值大的时候权重会变小。 主要还是应用权重来解决不平衡的问题。 还有一个部分是边界损失 想法比较简单，用groundtruth计算出边界部分，然后在预测值对这一部分进行损失计算，对各像素损失求和。 代码链接：（https://github.com/LIVIAETS/surface-loss） ConservativeLoss 核心思想是为了在不同领域的适应能力中，有较强的泛化性。对表现极度好的结果进行惩罚，从而鼓励中等表现得结果。如图所示，根据置信度来计算CL loss，相应得进行惩罚。$\\lambda$为5， $a$为$e$。 combo loss代码地址：https://github.com/asgsaeid/ComboLoss/blob/master/combo_loss.pydice loss + weighted ce$\\beta$控制 假阳性和假阴性的权重，大于0.5惩罚假阳性，小于0.5惩罚假阴性。$a$控制dice loss 和weighted ce loss的权重。 边界部分有权重的loss Active Contour Loss代码地址：（https://github.com/xuuuuuuchen/Active-Contour-Loss/blob/master/Active-Contour-Loss.py） - 最终的loss是Length 和Region 的和，代码中$\\lambda$设为的1，这是一个超参数。 - 首先看一下整个损失，它的计算方式都是用的差的平方的形式。 - 然后Length loss部分，只用了pred的信息，最小化梯度的大小，在这里我的理解是，它想达到的目的是让物体的内部尽量平滑，只有边界部分有这个梯度的变化。 - 接着是Region部分，使用label的监督信息对每一个点进行监督训练。 - 总结一下整个地方，感觉在边界部分，这两个Loss有冲突的地方，Length损失在边界部分会变大，但是它因为没有监督信息，它趋向于对所有位置都平滑处理，但是Region部分有监督信息，为了让边界部分损失变小会将物体和边界分开。也因为是用的差的平方的形式，边界部分的预测值概率应该是平滑下降的，骤降的loss太大，也就是惩罚太大。感觉是对整个预测结果作了一个平滑处理。 Distance Map Loss Penalty Term for Semantic Segmentation$\\phi$代表 边界的距离图，如图所示：结合上面的公式，就代表着边界部分的权重会高于其他地方，其他的没有改动。 NonAdjacencyLoss代码地址：https://github.com/trypag/NonAdjLoss创新点是加入了各个类之间的邻接矩阵，用一个子网络去预测这个矩阵。即可以监督学习也可以半监督的学习。前面一部分是一般的损失，如dice或交叉熵等，后面是用邻接矩阵加的限定损失。 求$a_{ij}\\left( \\phi \\right)$这个过程是离线的过程，根据总的有标签的数据求一个最后求和的邻接矩阵“模板”。形成一个先验的知识，对于半监督无标签时，这个G(w)这一项的损失也可以根据这个“模板”进行计算。对于医疗图像来说，这样做也是有一定道理的。但是我自己认为这样做会无法考虑到空间中的信息，只是考虑了类与类之间的信息。","link":"/2020/02/04/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E4%B8%AD%E7%9A%84loss%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"icarus","slug":"icarus","link":"/tags/icarus/"},{"name":"点云","slug":"点云","link":"/tags/%E7%82%B9%E4%BA%91/"},{"name":"图像语义分割","slug":"图像语义分割","link":"/tags/%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"}],"categories":[{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"点云","slug":"学习/点云","link":"/categories/%E5%AD%A6%E4%B9%A0/%E7%82%B9%E4%BA%91/"},{"name":"自定义博客","slug":"学习/自定义博客","link":"/categories/%E5%AD%A6%E4%B9%A0/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%8D%9A%E5%AE%A2/"},{"name":"图像语义分割","slug":"学习/图像语义分割","link":"/categories/%E5%AD%A6%E4%B9%A0/%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"}]}